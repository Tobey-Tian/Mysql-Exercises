{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1.Get real data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run code in gcp first to get the outputUriPrefix\n",
    "$ gcloud firestore export gs://mmtc-staging.appspot.com -- collection-ids=analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(outputUriPrefix):\n",
    "    from google.cloud import bigquery\n",
    "    from google.oauth2 import service_account\n",
    "    from googleapiclient.discovery import build\n",
    "    from datetime import date\n",
    "    import os\n",
    "    from flask import Flask, request\n",
    "    #!pip install google-api-python-client'\n",
    "    \n",
    "    def create_table(outputUriPrefix):\n",
    "        \"\"\"create table in bigquery\"\"\"\n",
    "        global client\n",
    "        global today\n",
    "        global table_id\n",
    "\n",
    "        client = bigquery.Client(project='mmtc-staging')\n",
    "        dataset_id = 'analytics'\n",
    "\n",
    "        source_uris = outputUriPrefix + \"/all_namespaces/kind_analytics/all_namespaces_kind_analytics.export_metadata\"\n",
    "\n",
    "        # Configure the external data source\n",
    "        dataset_ref = client.dataset(dataset_id)\n",
    "\n",
    "        today = date.today().strftime(\"%m%d%y\")\n",
    "        table_id = \"latest_dataset_\" + today\n",
    "        #print(table_id)\n",
    "\n",
    "        table = bigquery.Table(dataset_ref.table(table_id))\n",
    "        job_config = bigquery.LoadJobConfig()\n",
    "        job_config.source_format = \"DATASTORE_BACKUP\"\n",
    "        job_config.write_disposition = \"WRITE_TRUNCATE\"\n",
    "\n",
    "        load_job = client.load_table_from_uri(source_uris,\n",
    "                                              dataset_ref.table(table_id),\n",
    "                                              job_config=job_config)\n",
    "\n",
    "    \n",
    "    # run upper code in GCP console and replace the following path with the latest one\n",
    "    outputUriPrefix = outputUriPrefix\n",
    "    # create latest table\n",
    "    create_table(outputUriPrefix)\n",
    "    \n",
    "    table = client.get_table(\"mmtc-staging.analytics.\"+table_id)  # Make an API request.\n",
    "\n",
    "    original_schema = table.schema\n",
    "    new_schema = original_schema[:]  # Creates a copy of the schema.\n",
    "    #new_schema.append(bigquery.SchemaField(\"FundingSource\", \"STRING\"))\n",
    "    new_schema.append(bigquery.SchemaField(\"AppraisedValue\", \"FLOAT\"))\n",
    "\n",
    "    table.schema = new_schema\n",
    "    table = client.update_table(table, [\"schema\"])  # Make an API request.\n",
    "    \n",
    "    # perform a query\n",
    "    query = \"\"\"\n",
    "    SELECT ID, FundingSource, LTV, State, LoanProcessor,LoanOfficer, LoanAmount, \n",
    "           IF((ABS(TimeWindow)>1000),0,TimeWindow) AS TimeWindow, \n",
    "           AppraisedValue\n",
    "    FROM  \n",
    "      (SELECT ID, FundingSource, LTV, State, LoanProcessor,LoanOfficer, LoanAmount, AppraisedValue, \n",
    "              (DATETIME_DIFF(parse_datetime('%m/%d/%Y',CloseDate), parse_datetime('%m/%d/%Y',SignedDate), DAY)) AS TimeWindow    \n",
    "       FROM\n",
    "            (SELECT  \n",
    "                LoanOriginationSystem_LoanOriginationSystemLoanIdentifier AS ID,\n",
    "                IFNULL(FundingSource_FullName,'TBD_FS') AS FundingSource, \n",
    "                IFNULL(SubjectLoan_AppraisedARLTVRatioPercent.float, 0) AS LTV,\n",
    "                IFNULL(SubjectProperty_StateCode,\"UNKNOWN\") AS State,\n",
    "                IFNULL(SubjectLoan_BorrowerRequestedLoanAmount,0) AS LoanAmount,\n",
    "                IFNULL(AppraisedValue,0) AS AppraisedValue,\n",
    "                IFNULL(REPLACE(LenderRepresentative_LenderRepresentativeSignatureName,' ',''),'TBD_LP') AS LoanProcessor,\n",
    "                IFNULL(REPLACE(LoanOfficer_FullName,' ',''),'TBD_LO') AS LoanOfficer,\n",
    "                IF(REGEXP_CONTAINS(SubjectLoan_LoanEstimatedClosingDate, '^[0-9]'), \n",
    "                    SubjectLoan_LoanEstimatedClosingDate, \"01/01/2000\") AS CloseDate,\n",
    "                IF(REGEXP_CONTAINS(Borrower_BorrowerApplicationSignedDate, '^[0-9]'), \n",
    "                    Borrower_BorrowerApplicationSignedDate, \"01/01/2000\") AS SignedDate\n",
    "            FROM\n",
    "              `mmtc-staging.analytics.latest_dataset_{}`) AS Table_1)\n",
    "    WHERE \n",
    "        ID IS NOT NULL\n",
    "    \"\"\".format(today)\n",
    "\n",
    "    query_job = client.query(query)  # Make an API request.\n",
    "    df = query_job.to_dataframe()\n",
    "    df = df.set_index(\"ID\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2. Get train data and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(train_data, real_X):\n",
    "  import pandas as pd\n",
    "  from sklearn.feature_extraction import DictVectorizer\n",
    "  \"\"\"Read input data and split it into train and test.\"\"\"\n",
    "  data = pd.read_csv(train_data)\n",
    "  data.dropna(axis=0, subset=['Closed'], inplace=True)\n",
    "  data = data.set_index('LoanNo.')\n",
    "  count1, count0 = data['Closed'].value_counts()\n",
    "  closed = data[data.Closed==1]\n",
    "  withdraw = data[data.Closed==0]\n",
    "  overwd = withdraw.sample(count1, replace=True)\n",
    "  oversample = pd.concat([closed,overwd], axis=0)\n",
    "\n",
    "  train_y = oversample.Closed\n",
    "  train_X = oversample.drop(['Closed'], axis=1)\n",
    "  test_X = real_X\n",
    "\n",
    "  vec = DictVectorizer() \n",
    "  train_X = train_X.to_dict(orient='records')\n",
    "  train_X = vec.fit_transform(train_X).toarray()\n",
    "  test_X = test_X.to_dict(orient='records')\n",
    "  test_X = vec.transform(test_X).toarray()\n",
    "\n",
    "  return (train_X, train_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_X,\n",
    "                train_y,\n",
    "                n_estimators,\n",
    "                max_depth,\n",
    "                learning_rate):\n",
    "  from xgboost import XGBClassifier\n",
    "  \"\"\"Train the model using XGBRegressor.\"\"\"\n",
    "  model = XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "  model = model.fit(train_X,\n",
    "            train_y)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Make prediction on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_predict(model, test_X, real_X):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  pred_cls = model.predict(test_X)\n",
    "  pred_prob = model.predict_proba(test_X)\n",
    "  cls_df = pd.DataFrame(data = pred_cls, \n",
    "                      columns = [\"pred_class\"], \n",
    "                      index = real_X.index.copy())\n",
    "  prob_df = pd.DataFrame(data = np.round(pred_prob, 4), \n",
    "                       columns = [\"prob_0\", \"prob_1\"], \n",
    "                       index = real_X.index.copy())\n",
    "\n",
    "  prob_df = pd.merge(prob_df, cls_df, how = \"left\", \n",
    "                   left_index = True, right_index = True)\n",
    "  full_df = pd.merge(real_X, prob_df, how = \"left\", \n",
    "                   left_index = True, right_index = True)\n",
    "  return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4. Add the prection results to firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred(full_df):\n",
    "    from google.cloud import firestore\n",
    "    for ID in (full_df.index):\n",
    "        prec = float(full_df.prob_1[full_df.index == ID])\n",
    "    def create_close_perc(ID, prec):\n",
    "        db = firestore.Client(project='mmtc-staging')\n",
    "        \"\"\"Create or overwrite a single document\"\"\"\n",
    "        analytics_ref = db.collection(u'analytics').document(ID)\n",
    "        analytics_ref.set({\n",
    "        u'SubjectLoan_PredictedClosingPercent': prec\n",
    "    }, merge=True)\n",
    "        return\n",
    "    create_close_perc(ID, prec)\n",
    "    print('accomplished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5. Save Model as joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file):\n",
    "  import logging\n",
    "  import joblib\n",
    "  \"\"\"Save XGBoost model for serving.\"\"\"\n",
    "  joblib.dump(model, model_file)\n",
    "  logging.info(\"Model export success: %s\", model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_X = retrieve_data(\"gs://mmtc-staging.appspot.com/2020-07-31T17:25:04_27449\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y, test_X)=read_input('test_new.csv',real_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=train_model(train_X,\n",
    "                train_y,\n",
    "                300,5,\n",
    "                0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = real_predict(model, test_X, real_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FundingSource</th>\n",
       "      <th>LTV</th>\n",
       "      <th>State</th>\n",
       "      <th>LoanProcessor</th>\n",
       "      <th>LoanOfficer</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>TimeWindow</th>\n",
       "      <th>AppraisedValue</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778808f-33e7-4f66-b02d-f051b0d720f8</th>\n",
       "      <td>TBD_FS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>TBD_LP</td>\n",
       "      <td>MeganTrammel</td>\n",
       "      <td>420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24c0ceef-ac92-4fcc-86ec-20a643f3f4b4</th>\n",
       "      <td>TBD_FS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>TBD_LP</td>\n",
       "      <td>AaronPfeffer</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29a60b1e-0540-4a43-8365-40d496eace1f</th>\n",
       "      <td>TBD_FS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>TBD_LP</td>\n",
       "      <td>HerbBourdeaux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4df33c06-ded2-42ce-a937-0358aa4db42e</th>\n",
       "      <td>TBD_FS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>TBD_LP</td>\n",
       "      <td>TBD_LO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.4599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54eeb0f8-df00-4390-a52a-242baa0fe59e</th>\n",
       "      <td>TBD_FS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>TBD_LP</td>\n",
       "      <td>SusanAubin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4240</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     FundingSource  LTV    State  \\\n",
       "ID                                                                 \n",
       "1778808f-33e7-4f66-b02d-f051b0d720f8        TBD_FS  0.0  UNKNOWN   \n",
       "24c0ceef-ac92-4fcc-86ec-20a643f3f4b4        TBD_FS  0.0  UNKNOWN   \n",
       "29a60b1e-0540-4a43-8365-40d496eace1f        TBD_FS  0.0       AZ   \n",
       "4df33c06-ded2-42ce-a937-0358aa4db42e        TBD_FS  0.0  UNKNOWN   \n",
       "54eeb0f8-df00-4390-a52a-242baa0fe59e        TBD_FS  0.0  UNKNOWN   \n",
       "\n",
       "                                     LoanProcessor    LoanOfficer  LoanAmount  \\\n",
       "ID                                                                              \n",
       "1778808f-33e7-4f66-b02d-f051b0d720f8        TBD_LP   MeganTrammel      420000   \n",
       "24c0ceef-ac92-4fcc-86ec-20a643f3f4b4        TBD_LP   AaronPfeffer      300000   \n",
       "29a60b1e-0540-4a43-8365-40d496eace1f        TBD_LP  HerbBourdeaux           0   \n",
       "4df33c06-ded2-42ce-a937-0358aa4db42e        TBD_LP         TBD_LO           0   \n",
       "54eeb0f8-df00-4390-a52a-242baa0fe59e        TBD_LP     SusanAubin           0   \n",
       "\n",
       "                                      TimeWindow  AppraisedValue  prob_0  \\\n",
       "ID                                                                         \n",
       "1778808f-33e7-4f66-b02d-f051b0d720f8           0             0.0  0.0026   \n",
       "24c0ceef-ac92-4fcc-86ec-20a643f3f4b4           0             0.0  0.4659   \n",
       "29a60b1e-0540-4a43-8365-40d496eace1f           0             0.0  0.8662   \n",
       "4df33c06-ded2-42ce-a937-0358aa4db42e           0             0.0  0.5401   \n",
       "54eeb0f8-df00-4390-a52a-242baa0fe59e           0             0.0  0.4240   \n",
       "\n",
       "                                      prob_1  pred_class  \n",
       "ID                                                        \n",
       "1778808f-33e7-4f66-b02d-f051b0d720f8  0.9974           1  \n",
       "24c0ceef-ac92-4fcc-86ec-20a643f3f4b4  0.5341           1  \n",
       "29a60b1e-0540-4a43-8365-40d496eace1f  0.1338           0  \n",
       "4df33c06-ded2-42ce-a937-0358aa4db42e  0.4599           0  \n",
       "54eeb0f8-df00-4390-a52a-242baa0fe59e  0.5760           1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accomplished!\n"
     ]
    }
   ],
   "source": [
    "add_pred(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Initiate Kubeflow pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kfp --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Convert Python scripts to docker containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import kfp\n",
    "from kfp import components as comp\n",
    "from kfp import dsl\n",
    "import os\n",
    "import subprocess\n",
    "train_op = comp.func_to_container_op(train_model, base_image='tensorflow/tensorflow:latest-gpu-py3')\n",
    "predict_op = comp.func_to_container_op(real_predict, base_image='tensorflow/tensorflow:latest-gpu-py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Define Kubeflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host='31b386be1f929b65-dot-us-central2.pipelines.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='AnalyticsPipeline_1',\n",
    "   description='A pipeline that performs closing possibility model training and prediction.'\n",
    ")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def analytics_container_pipeline(\n",
    "    data_path: \"gs://mmtc-staging.appspot.com/2020-07-31T17:25:04_27449\",\n",
    "    model_file: \"mmtc-staging\", \n",
    "    image_number: int\n",
    "):\n",
    "    \n",
    "    # Define volume to share data between components.\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"create_volume\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWM)\n",
    "    \n",
    "    # Create training component.\n",
    "    analytics_training_container = train_op(data_path, model_file) \\\n",
    "                                    .add_pvolumes({data_path: vop.volume})\n",
    "\n",
    "    # Create MNIST prediction component.\n",
    "    analytics_predict_container = predict_op(\"gs://mmtc-staging.appspot.com/2020-07-31T17:25:04_27449\", model_file, image_number) \\\n",
    "                                    .add_pvolumes({data_path: mnist_training_container.pvolume})\n",
    "    \n",
    "    # Print the result of the prediction\n",
    "    mnist_result_container = dsl.ContainerOp(\n",
    "        name=\"print_prediction\",\n",
    "        image='library/bash:4.4.23',\n",
    "        pvolumes={data_path: mnist_predict_container.pvolume},\n",
    "        arguments=['cat', f'{data_path}/result.txt']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
